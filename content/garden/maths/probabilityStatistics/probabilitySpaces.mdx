import Callout from "@components/Callout/Callout";
import Image from "@components/Image/Image";

# Probability Spaces

A lot of systems are very complex. For example describing the motion of water molecules or the stock market. In such cases, it can be impossible to describe the system in such great detail to predict specific outcomes. Instead, we use 
**probabilistic models** to describe the system. These probabilistic models use and follow the rules of probability theory.

Another example of a complex system is quantum theory. For most already the name is enough to make them shiver. But in 1900 Max Planck came up with some building blocks to describe the system of quantum theory using probability theory. This was the birth of quantum theory. This was highly controversial at the time because physicists were used to deterministic models, i.e models that were able to predict outcomes with certainty. Einstein was one of the most vocal critics of quantum theory. He famously said "God does not play dice with the universe" and one of his life goals was to find a deterministic model for quantum theory. But so far no one has been able to do so.

These probabilistic models are based on the concept of a **probability space**, a mathematical model that describes the possible outcomes of a random experiment and the probability of each outcome.

## Random Experiments

First of all, we need to define what a **random experiment** is. A random experiment or also called trial is an experiment that can be repeated arbitrarily often and leads to a mutually exclusive and exhaustive set of outcomes. 

What does this mean? Mutually exclusive outcomes means that only one of the outcomes can happen at a time. Two outcomes 
can not happen at the same time. Exhaustive means that one of the outcomes must happen. There are no other outcomes. 

Importantly, the outcome of a random experiment is not predictable with certainty beforehand, there is always some element of randomness involved. This is why it is called a random experiment and is the reason why we need probability theory to describe the system.

Some common examples of random experiments are flipping a coin, rolling a die. (We assume that the coin is fair and the die is fair and there is no cheating involved). 


<Image 
    src="/maths/einsteinDice.jpeg" 
    caption="Generated by AI"
    width={400}
/>

With this knowledge, we could already informally describe a probabilistic model of a coin flip. We could say that there 
are two possible outcomes: heads or tails and that the probability of each outcome is 0.5. A different probabilistic model for the random experiment of flipping a coin could also be if we include the outcome of the coin landing on its side and giving it a very small probability of happening. We could also use a biased coin that has a higher probability of landing on heads than on tails.

It turns out that flipping a coin isn't actually fair, i.e the probability of heads and tails isn't 0.5. You can 
watch [this video by Numberphile](https://www.youtube.com/watch?v=AYnJv68T3MM) to know more.

### Law of Large Numbers

The interesting thing about random experiments is when you perform the experiment once you can not predict the outcome. But if you perform the experiment multiple times you can predict the outcome. For example, if you flip a coin once you can not predict if it will land on heads or tails. But if you flip the coin 1000 times you can predict that it will land on heads roughly 500 times and tails roughly 500 times. This is called the law of large numbers. 

## Sample Space

If we want to model a random experiment we first need a set of all the possible outcomes of the random experiment. This set is called the **sample space** and is denoted by $\Omega$. The elements of the sample space are the mutually exclusive and exhaustive outcomes of the random experiment which are denoted by $\omega \in \Omega$ and are also 
often called **elementary events**, **elementary experiments** or **states**.

We've seen what mutually exclusive means that they cannot occur simultaneously. For example a coin cannot land on heads and tails at the same time. So we could formally write our sample space for a coin flip as:

```math
\Omega = \{\text{Heads}, \text{Tails}\}
```

We've also seen that our model should be exhaustive, i.e our sample space should contain all possible outcomes. The number of outcomes in the sample space can vary depending on the random experiment but we will see more about this later.

## Events

An **event** is a set of outcomes. In other words, an event is a subset of the sample space $A \subseteq \Omega$. We can then get the set of all possible events by taking the [power set](/garden/maths/discrete/setTheory#power-set) of the sample space $\mathscr{P}(\Omega)$. 

Say we then perform a random experiment and the experiment results in the outcome $\omega$ so $\omega \in \Omega$. 
- We then say if $\omega \in A$ then the event $A$ has occurred.
- If $\omega \notin A$ then the event $A$ has not occurred.

This then leads to two special events that can easily be defined and interpreted:
- The **impossible event** is the empty set $\emptyset$. This corresponds to an event that will never occur. 
- The **certain/sure/guaranteed event** is the sample space $\Omega$. This corresponds to an event that will always occur.

<Callout type="example">
We have already defined the sample space for rolling a six-sided die as $\Omega = \{1,2,3,4,5,6\}$. We can now construct the following events, i.e subsets of the sample space:

- Rolling an even number: $A=\{2,4,6\}$
- Rolling a number divisible by 3: $A=\{3,6\}$
- Rolling a number greater than 2: $A=\{3,4,5,6\}$
- Rolling a seven: $A=\emptyset$, i.e the impossible event since our die only has numbers from 1 to 6.
- Rolling a number between 1 and 6: $A=\Omega$, i.e the certain event since we are guaranteed to roll a number from 1 to 6.
</Callout>

### Sigma Algebra

In some cases we might not want to consider all possible events. For example when the sample space $\Omega$ is very large. In such cases we can define a **sigma algebra** denoted by $\F$ which is a specific collection of events that we are interested in. To make sure that all the properties of probability theory hold we need to make sure that the sigma algebra satisfies some specific properties.

Firstly the certain event must be in the sigma algebra so:

```math
\Omega \in \F
```

Secondly if an event is in the sigma algebra then the complement of that event must also be in the sigma algebra:

```math
A \in \F \Rightarrow A^c \in \F
```

Lastly if we have some events in the sigma algebra then the union of these events must also be in the sigma algebra:

```math
A_1,A_2,... \in \F \Rightarrow \bigcup_{i=1}^{\infty} A_i \in \F
```

These properties ensure that the sigma algebra is closed under the operations of complement and union. This is important because we want to be able to calculate the probability of complex events by breaking them down into their elementary parts which we will see later. 

<Callout type="example">

</Callout>

The above properties also have some consequences.

vennAllPossibilities.png

## Probability Measure

So far we actually haven't seen any probabilities. We have only defined what experiments are and what outcomes or events can occur. We haven't defined with what probability these outcomes or events occur. This is where the **probability measure** comes in. The probability measure is a map that assigns a probability to each event in the sample space. More formally we can define the probability measure on a sample space $\Omega$ and a sigma algebra $\mathcal{F}$ as:

```math
\begin{align*}
\P: &\F \to [0,1]
&A \mapsto \P(A)
\end{align*}
```

And that satisfies some properties. We can see that each event $A$ is assigned a probability $\P(A)$ which is a number between 0 and 1. 1 means that the event is certain to happen and 0 means that the event is impossible. This leads to the first property that the probability measure must satisfy. 

```math
\P[\Omega] = 1
```
so the probability of the certain event is 1 as it will always occur. The next property is called **countable additivity** or sometimes also **sigma additivity**. This property states that the probability of the union of mutually exclusive events is equal to the sum of the probabilities of the individual events. 

```math
\P[A] = \sum_{i=1}^{\infty} \P[A_i] \text{ where } A = \bigcup_{i=1}^{\infty} A_i \text{ and } A_i \cap A_j = \emptyset \text{ for } i \neq j \text{so a disjoint union}
```

This property is very important because it allows us to calculate the probability of complex events by breaking them down into its disjoint parts which at the lowest level are the probabilities of the elementary events or outcomes.

<Callout type="example">
We can now define the probability measure for the sample space of rolling a six-sided die. We can say that each outcome is equally likely so the probability of each outcome is $\frac{1}{6}$. So the probability measure for the sample space is:

```math
\P(\{1\}) = \frac{1}{6}, \P(\{2\}) = \frac{1}{6}, \ldots, \P(\{6\}) = \frac{1}{6}
```

We can now calculate the probability of more complex events by breaking them down into their disjoint parts. For example, the probability of the event "rolling an even number" is:

```math
\P(\{2,4,6\}) = \P(\{2\}) + \P(\{4\}) + \P(\{6\}) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{1}{2}
```

Which matches our intuition that the probability of rolling an even number is $\frac{1}{2}$.
</Callout>

### Finite Sample Space

This is the simplest case. The sample space contains only a finite number of outcomes:

```math
\Omega = \{\omega_1,\omega_2,\omega_3,...\omega_n\}
```

Where $n$ is the number of possible outcomes and $n \in \mathbb{N}$.

<Callout type="example" title="Example Finite Sample Space">
We are playing dungeons and dragons and we are rolling a 20-sided die. Then the sample space is:
```math
\Omega = \{1,2,3, \ldots, 20\}
```
</Callout>

### Countable Sample Space

Contains infinitely many elementary events, but they can be numbered like the natural numbers.

<Callout type="example" title="Example Countably Infinite Sample Space">
We roll a die until we get a 6 for the first time. Theoretically, this could take forever, but we can count the number of rolls until the first 6 appears.

Thus, we have $\omega_i = i$ for $i=(1,2,...)$ and

```math
\Omega = \{1,2,3,...\}
```
</Callout>

## Combination of Events

As we have seen, events are just sets, meaning we can perform set operations on them.

### Union

For the union of events $A \cup B$, we can say that either $A$ or $B$ occurs or both occur simultaneously.

### Intersection

The intersection of events $A \cap B$ states that $A$ and $B$ occur simultaneously.

### Complement

The complement of $A$, denoted as $A^c$ or often written as $\overline{A}$, means that $A$ does not occur.

<Callout type="example" title="Example Combination of Events When Rolling a Die">
If we define the events "rolling an even number" and "rolling an odd number" as $A=\{2,4,6\}$, $B=\{1,3,5\}$, then:

- $\overline{A}=B$
- $\overline{B}=A$
- $A \cup B = \Omega$
- $A \cap B = \emptyset$

which all make sense when considered logically.
</Callout>

## De Morgan's Laws

De Morgan's laws also apply to events:

```math
\begin{align*}
    \overline{A \cup B} &= \overline{A} \cap \overline{B} \\
    \overline{A \cap B} &= \overline{A} \cup \overline{B}
\end{align*}
```

## Laplace Experiments

If all elementary events in a random experiment have the same probability of occurring, meaning all outcomes are **equally likely**, we speak of a Laplace experiment. This is also called a uniform distribution.

For a sample space of size $|\Omega|=m$ with $m$ equally likely elementary events, we have a **Laplace space**. Each elementary event $\omega_i$ has the same probability, known as **counting density**:

```math
P(\{\omega_i\}) = p(\omega_i)= \frac{1}{m} \text{ with } i=1,2,...,m
```

Thus, the probability of an event $A$ is defined as:

```math
P(A) = \sum_{\omega_i \in A}{p(\omega_i)} = |A| \cdot \frac{1}{m} = \frac{|A|}{m}
```

<Callout type="example" title="Example Laplace Experiment: Rolling a Die">
When rolling a die, all 6 outcomes are equally likely, making it a Laplace experiment.

For each elementary event, $p(\omega_i) = \frac{1}{6}$

For the event "even number," $A = \{2,4,6\}$, the probability is:

```math
P(A)=\frac{3}{6} = \frac{1}{2} = 50\%
```
</Callout>

## Kolmogorov's Axioms

Probability is a function $P$ that assigns each event $E \subseteq \Omega$ a number $P(E) \in [0,1]$.

```math
P: 2^{\Omega} \mapsto [0,1]
```

### Axiom 1

$P(E)$ is a non-negative number at most equal to 1:

```math
0 \leq P(E) \leq 1
```

### Axiom 2

For the certain event $\Omega$:

```math
P(\Omega)=1
```

### Axiom 3

For pairwise mutually exclusive events $A_1,A_2,A_3,...$:

```math
P(A_1 \cup A_2 \cup A_3, ...) = P(A_1)+P(A_2)+P(A_3)+ ...
```

## Conditional Probability

The conditional probability of $B$ given $A$ is defined as:

```math
P(B | A)= \frac{P(A \cap B)}{P(A)}
```

## Multiplication Rule

Rearranging the conditional probability formula gives the multiplication rule:

```math
P(A \cap B)=P(A) \cdot P(B|A)
```

```math
P(A) \cdot P(B|A) = P(B) \cdot P(A|B)
```

## Stochastic Independence

It is possible that the probability of an event $B$ depends on another event $A$. This leads us to the concept of conditional probability.

However, if this is not the case, meaning that the events do not depend on each other, we refer to such events as **stochastically independent**. In this case, the following holds:

```math
P(A | B) = P(A) \text{ and } P(B | A) = P(B)
```

From the multiplication rule, we then get:

```math
P(A \cap B)=P(A) \cdot P(B|A)=P(A) \cdot P(B)
```

Thus, we can define that two events are stochastically independent if:

```math
P(A \cap B)= P(A) \cdot P(B)
```

<Callout type="example" title="Example: Stochastically Independent Coin Tosses">

A coin is tossed three times, and we consider the following events:

- $A=$ Heads on the 1st toss
- $B=$ Heads on the 2nd toss
- $C=$ Tails on the 3rd toss

They are all stochastically independent since they do not influence each other.

</Callout>

## Multi-Stage Random Experiments

In a multi-stage random experiment, multiple random experiments are conducted sequentially. These are often represented using tree diagrams (event trees), distinguishing between final outcomes and intermediate outcomes.

We define the following rules:

1. The probabilities along a path are multiplied together.
2. If multiple paths lead to the same final outcome, their probabilities are added.

A good video explanation can be found [here](https://studyflix.de/statistik/baumdiagramm-1107).

<Callout type="example" title="Example: Multi-Stage Random Experiment">

An urn contains 6 balls: 2 white and 4 black. We randomly draw 2 balls one after another without replacement, meaning 2 stages. We ask: What is the probability of drawing 2 balls of the same color ($A$) or 2 balls of different colors ($B$)?

**Stage 1:**

- $P(W) = {2 \over 6} = {1 \over 3}$
- $P(S) = {4 \over 6} = {2 \over 3}$

**Stage 2:**
After the first draw, only 5 balls remain. If a white ball was drawn:

- $P(W|W) = {1 \over 5}$
- $P(S|W) = {4 \over 5}$

If a black ball was drawn:

- $P(W|S) = {2 \over 5}$
- $P(S|S) = {3 \over 5}$

The results are:

For same-colored balls:

```math
P(A)=P(WW) + P(SS) = {1 \over 3} \cdot {1 \over 5} + {2 \over 3} \cdot {2 \over 5} = {7 \over 15}
```

For differently-colored balls:
```math
P(A)=P(WS) + P(SW) = {1 \over 3} \cdot {4 \over 5} + {2 \over 3} \cdot {2 \over 5} = {8 \over 15}
```

![multi-stage-random-experiment](/maths/mehrstufigeZufallsexperimente.png)

</Callout>

## Law of Total Probability

The **total probability** for an event $B$, where $A_i$ are the possible intermediate events leading to $B$, is given by:

```math
P(B)= \sum_{i=1}^{n}{P(A_i)\cdot P(B|A_i)}
```

A good video explanation can be found [here](https://studyflix.de/statistik/satz-der-totalen-wahrscheinlichkeit-1111) and [here](https://www.youtube.com/watch?v=0iJSW0VNddo).

## Bayes' Theorem

Given that event $B$ has already occurred, the probability that it happened via intermediate event $A_j$ is given by Bayes' theorem:

```math
P(A_j|B)= {P(A_j \cap B) \over P(B)} = {P(A_j) \cdot P(B | A_j) \over P(B)}
```

A good video explanation can be found [here](https://studyflix.de/statistik/satz-von-bayes-1113) and [here](https://www.youtube.com/watch?v=wUDxQFbXqjA).

## Birthday Paradox

The birthday paradox is an example of how certain probabilities are often misestimated intuitively.

We ask: "What is the probability that at least two people in a group of $k$ people share the same birthday?"

To answer this, we first consider the probability that **no** two people share a birthday:

For 2 people: ${365 \over 365} \cdot {364 \over 365}$  
For 3 people: ${365 \over 365} \cdot {364 \over 365} \cdot {363 \over 365}$  
etc.  

This probability approaches 0 as $k$ increases. Thus, we can answer our question as follows:

```math
P(\text{same})=1-P(\text{different}) \Leftrightarrow P(A)=1- \frac{365 \cdot (365-1)\cdot...\cdot (365-n+1)}{365^n}
```

## Bernoulli Experiment

A Bernoulli experiment is a random experiment with exactly two possible outcomes: success or failure.

A common example is rolling a die. We are only interested in whether we roll a 6. That is, rolling a 6 is considered a success, while all other outcomes are grouped together as a failure.

Unlike a Laplace experiment, the probabilities of the outcomes do not necessarily have to be equal. In the example above, the probability of success is $\frac{1}{6}$.

