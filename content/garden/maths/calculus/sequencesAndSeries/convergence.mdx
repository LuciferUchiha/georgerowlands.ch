import Callout from "@components/Callout/Callout";
import Image from "@components/Image/Image";

# Convergence of Sequences and Series

If we analyze the values of a [sequence](/garden/maths/calculus/sequencesAndSeries/sequences) we can see that certain behaviors or patterns can occur such as the sequence becoming [monotonically increasing or decreasing](/garden/maths/calculus/sequencesAndSeries/sequences#monotonic-sequences) or the sequence staying within a certain range, i.e. being [bounded between two values](/garden/maths/calculus/sequencesAndSeries/sequences#bounded-sequences).

Another pattern we may notice is that the terms of the sequence get closer and closer to a certain value as the index $n$ increases. Let's consider the following sequence and its terms:

```math
a_n = \frac{2n+3}{n} \text{ with } n \in \mathbb{N}
```

| $a_1$ | $a_2$ | $a_3$ | $a_{10}$ | $a_{1000}$ | $a_{100000}$ |
| ----- | ----- | ----- | -------- | ---------- | ------------ |
| 5     | 3.5   | 3     | 2.3      | 2.003      | 2.00003      |

As $n$ grows larger, the terms of the sequence get closer and closer to 2. This value is called the limit of the sequence. If the terms of the sequence get closer to some value as $n$ increases, then we say the sequence converges to that value. If the terms of the sequence do not get close to a certain value, then we say the sequence diverges. Another common phrasing is that as $n$ approaches infinity, the terms of the sequence approach the limit. We can formally write this as:

```math
\lim_{n \to \infty} \frac{2n+3}{n} = 2
```

Another common way to refer to the limit is by saying that the limes of the sequence is 2. The limes is the latin word for limit.

## Epsilon-Neighborhood

To formally define the limit of a sequence, we first introduce the concept of an **epsilon neighborhood (or epsilon strip)**. This is a region around a suspected limit with a radius of $\epsilon$, where $\epsilon > 0$. 

<Image 
    src="/maths/epsilonsNeighborhood.svg"
    caption="Epsilon neighborhood around the limit a with radius epsilon and entry index"
    width={500}
/>

The index of the term that first enters this neighbourhood is called the **dipping number** or **entry index**, and is denoted as $N_{\epsilon}$ or $N_0$. So for example if we have a sequence $a_n$ that converges to a limit $L$, then for every $\epsilon > 0$ we can define the neighborhood around $L$ as:

```math
\{n \in \mathbb{N} | |a_n - L| < \epsilon\} \text{or} \{n \in \mathbb{N} | a_n \in (L-\epsilon, L+\epsilon)\}
```

The entry index $N_{\epsilon}$ is the index of the term that first enters this neighborhood. This means that for all $n \geq N_{\epsilon}$, the terms $a_i$ are in the neighborhood around $L$, i.e. $a_i \in (L-\epsilon, L+\epsilon) \forall i \geq N_{\epsilon}$. 

<Callout type="example">
For a given sequence $a_n = \frac{2n+3}{n}$ and $\epsilon = 0.1$, we can calculate the entry index $N_{0.1}$ by solving the inequality:

```math
\begin{align*}
\left|\frac{2n+3}{n} - 2\right| < 0.1 \\
\left|\frac{3}{n}\right| < 0.1 \\
\frac{3}{n} < 0.1 \\
3 = 0.1n \\
n = 30
\end{align*}
```

So for $\epsilon = 0.1$, the entry index $N_{0.1} = 31$. We can check this by calculating the terms of the sequence for $n=29$, $n=30$, and $n=31$:

- $a_{29} = \frac{2*29+3}{29} = 2.1034$
- $a_{30} = \frac{2*30+3}{30} = 2.1$
- $a_{31} = \frac{2*31+3}{31} = 2.0968$

The entry index is 31 not 30 as the terms must be less than 0.1 away from the limit.
</Callout>

This is what D'Alembert and cauchy used to make the first definition of a limit. A sequence $a_n$ converges to a limit $L$ if for every $\epsilon > 0$ there exists an entry index $N_{\epsilon}$ such that for all $n \geq N_{\epsilon}$ the terms $a_n$ are in the $\epsilon$-neighborhood around $L$. In other words, after a certain point in the sequence, all terms are within $\epsilon$ of the limit.

Another way to define the limit is to say that a sequence $a_n$ converges to a limit $L$ if for every $\epsilon > 0$ there exists a finite number of terms in the sequence that are outside the $\epsilon$-neighborhood. These two definitions are equivalent. As in the first definition, there are a finite many terms outside the neighborhood, all 
terms where $n \leq N_{\epsilon}$ and which then means there are an infinite number of terms inside the neighborhood.

<Callout type="warning">
An important note is that the limit needs to be a real number if it is a real valued sequence. The limit can not be infinity as infinity is not a real number. So if a sequence converges to infinity, it is divergent.
</Callout>

We can show that the limit is unique, for this we assume there are two limits. Is rather intuitive proof and can also be shown visually.
limitUniqueness.png

We can show that all convergent sequences are bounded.

<Callout type="example">
an = a

an=n

an=1/n

an=(-1)^n

using archimedes principle to show that the limit of $a_n = \frac{n}{n+1} = 1$
</Callout>

Sind $a_n$ und $b_n$ konvergente Folgen mit den Grenzwerten $a$ bzw. $b$, so ist auch die Folge:

- $c*a_n$ konvergent mit $\lim_{n \to \infty} {c*a_n} = c*\lim_{n \to \infty} {a_n} = c*a$ f체r $c \in R$
- $a_n \pm b_n$ konvergent mit $\lim_{n \to \infty}{a_n \pm b_n}={{\lim_{n \to \infty}{a_n}} \pm {\lim_{n \to \infty}{b_n}}}={a \pm b}$
- $a_n *b_n$ konvergent mit $\lim_{n \to \infty}{a_n* b_n}={{\lim_{n \to \infty}{a_n}} * {\lim_{n \to \infty}{b_n}}}={a * b}$
- $a_n \over b_n$ konvergent mit $\lim_{n \to \infty}{a_n \over b_n}={{\lim_{n \to \infty}{a_n}} \over {\lim_{n \to \infty}{b_n}}}={a \over b}$ falls $b \neq 0$
- If there exists a $K \geq 1$ and $a_n \leq b_n$ for all $n \geq K$ then $\lim_{n \to \infty}{a_n} \leq \lim_{n \to \infty}{b_n}$ in other words $a \leq b$.

- Das Produkt einer beschr채nkten Folge und einer Nullfolge ist immer eine Nullfolge.

There are some important examples to look at. There is also a difference between proving a limit by definition and just calcualting it. 

$n^bq^n = 0$ Shows that any power of $n$ is smaller than any exponential function important for algorithms.

$n^{1\over n} = 1$

recursive defined sequences $a_{n+1} = 1 \over 2 (a_n + 2 \over a_n)$ goes to $\sqrt{2}$

$a_n = 1 \over 2 (a_{n-1} + c \over a_{n-1})$ and $a_1 = c$ using Weierstrass $c > 1$.

## Monotone Convergence Theorem

Theorem by Karl Weierstrass:

If the sequence $(a_n)_{n\geq 1}$ is monotonically increasing and bounded above, then it converges. More precisely we can determine the limit as:

```math	
\lim_{n \to \infty} a_n = \sup\{a_n | n \geq 1\}
```

The same holds for monotonically decreasing sequences that are bounded below. Here the limit uses the infimum instead of the supremum obviously.

```math
\lim_{n \to \infty} a_n = \inf\{a_n | n \geq 1\}
```

## Squeeze Theorem

The squeeze theorem or sometimes also called the sandwich theorem states that if we have three sequences $(a_n)_{n\geq 1}$, $(b_n)_{n\geq 1}$, and $(c_n)_{n\geq 1}$ such that:

```math	
a_n \leq b_n \leq c_n \text{ for all } n \geq 1 \text{ and } \lim_{n \to \infty} a_n = \lim_{n \to \infty} c_n = L
```

Then the sequence $(b_n)_{n\geq 1}$ also converges to $L$ so:

```math
\lim_{n \to \infty} b_n = L
```

## Bernoulli's Inequality

Does this come from probability theory?

```math
(1+x)^n \geq 1+nx \text{ for all } x \geq -1 \text{ and } n \in N
```	

## Euler's Number

Lots of possible origins but one is analyzing the compound interest formula.

```math
\lim_{n \to \infty} (1+{1\over n})^n = e
```

## Limes Superior and Inferior

## Important Sequences

### Artihmetic Sequences

### Zero Sequences

### Harmonic Sequences

**Nullfolge** eine Folge die den Grenzwert 0 besitzt.
**Harmonische Folge** $a_n={1\over n}$ ist eine Nullfolge

### Geometric Sequences

Folgen der Form: $a_n= a_1 *q^{n-1}$ sind geometrische Folgen.
 Jedes Glied ist das geometrische Mittel seiner beiden Nachbarglieder $a_n=\sqrt {a_{n-1}+a_{n+1}}$

Eine geometrische Folge $a_n= a_1* q^{n-1}$

- mit $|q|>1$ ist divergent
- mit $|q|<1$ ist konvergent mit Grenzwert 0
- mit $q=1$ ist eine konstante Folge $a_1$
- mit $q=-1$ ist divergent, da alternierend.

### Rational Sequences

F체r eine rationale Folge, die im Z채hler aus einem Polynom k-ten Grades
und im Nenner aus einem Polynom l-ten Grades besteht, gilt:
```math
 \lim_{n \to \infty}{{a_kn^k+a_{k-1}n^{k-1}+...+a_0}\over{b_ln^l+b_{l-1}n^{l-1}+...+b_0}} = \begin{dcases}
        {a_k\over b_k} *\infty, falls\space k >l \\
        {a_k\over b_k} , falls\space k=l \\
        0 , falls\space k<l
\end{dcases}
```

## Convergence of Series

We have seen that a [series](/garden/maths/calculus/sequencesAndSeries/series) is the sum of the terms of a [sequence](
/garden/maths/calculus/sequencesAndSeries/sequences). 

Just like sequences, series can also converge or diverge. A series converges if the sequence of partial sums converges. So in other words using the original sequence we calculate a new sequence, where each term is the sum of all terms up to that point. 

```math
\begin{align*}
\text{Sequence} & : (a_1, a_2, a_3, \ldots, a_n) \\
\text{Series} & : S_n = \sum^{n}_{k=1}{a_k} = a_1 + a_2 + a_3 + \ldots + a_n \\
\text{Sequence of partial sums} & : S_1, S_2, S_3, \ldots, S_n
\end{align*}
```

If the sequence of partial sums converges then the series converges. The limit of the sequence of partial sums is called the sum or value of the series. If the sequence of partial sums diverges then the series diverges.

For a series to converge the underlying sequence must be a null sequence, in other words the limit of the original sequence must be zero. This is a necessary but not sufficient condition. There are series that diverge even though the sequence of terms converges to zero.

```math
\sum_{n=1}^{\infty} a_n \text{ converges} \implies \lim_{n \to \infty} a_n = 0
```

There is an intuitive interpretation behind this condition. Imagine you're summing up the terms of a series. For the series to converge, the partial sums need to settle on a finite value as you keep adding more and more terms. If the terms of the sequence do not approach zero, it becomes impossible for the partial sums to settle, and the series will diverge. In short, if the terms are not getting smaller and smaller, the series will keep getting larger and larger and will not converge.

### Geometric Series

<Callout type="todo">
Shouldn't this be ar^k instead of just r^k?
</Callout>

Let's look at some example of series and analyze their convergence. The geometric series is a good example to start with. We define the geometric series for a value $q \in \mathbb{C}$ where $|q| < 1$ as:

```math
\sum^{\infty}_{k=0}{q^k}
```

For the series to converge we need to check if the sequence of partial sums converges. The sequence of partial sums is:

```math
\begin{align*}
S_n &= \sum^{n}_{k=0}{q^k} = 1 + q + q^2 + \ldots + q^n \\ 
q * S_n &= q + q^2 + q^3 + \ldots + q^{n+1} \\
S_n - q * S_n &= 1 - q^{n+1} \\
(1-q) * S_n &= 1 - q^{n+1} \\
S_n &= \frac{1 - q^{n+1}}{1-q}
\end{align*}
```

Now we have a closed form for the sequence of partial sums. We can now take the limit of the sequence of partial sums to see if the series converges. As $n \to \infty$ the term $q^{n+1}$ goes to zero as $|q| < 1$. So we can assume the limit exists and that it is $\frac{1}{1-q}$. Let's prove it is indeed the limit:

```math
\lim_{n \to \infty}\left|\frac{1 - q^{n+1}}{1-q} - \frac{1}{1-q}\right| = \lim_{n \to \infty}\left|\frac{1 - q^{n+1} - 1}{1-q}\right| = \lim_{n \to \infty}\left|\frac{- q^{n+1}}{1-q}\right| = \lim_{n \to \infty}\left|\frac{q^{n+1}}{1-q}\right| = 0
```

So sequence of partial sums converges to $\frac{1}{1-q}$ with $|q| < 1$, which means the geometric series converges to $\frac{1}{1-q}$.

<Callout type="example">
Let's look at the geometric series for $q = \frac{1}{2}$:

```math
\begin{align*}
\sum^{\infty}_{k=0}{\left(\frac{1}{2}\right)^k} &= 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \ldots \\
&= \frac{1}{1-\frac{1}{2}} = \frac{1}{\frac{1}{2}} = 2
\end{align*}
```

But what if the index starts at 1 rather than 0? Let's revist the closed form for the sequence of partial sums:

```math
\begin{align*}
\sum^{\infty}_{k=1}{q^k} &= q + q^2 + q^3 + \ldots \\
&= \sum^{\infty}_{k=0}{q^k} - q^0 = \frac{1}{1-q} - 1 = \frac{q}{1-q}
\end{align*}
```

We know that this sequence still converges. So we can say that what we do in the first steps does not have an effect on the convergence of the series. However, it does have an effect on the value of the series. So the geometric series for $q = \frac{1}{2}$ starting at 1 converges to $\frac{\frac{1}{2}}{1-\frac{1}{2}} = 1$ instead of 2.
</Callout>

### Harmonic Series

<Callout type="todo">
Add the proof for the harmonic series. Probably with Cauchy criterion.
</Callout>

```math	
\sum^{\infty}_{n=1}{\frac{1}{n}}
```

diverges. Despite the sequence of terms converging to zero, the series diverges. This is a good example to show that the terms of the sequence converging to zero is a necessary but not sufficient condition for the series to converge.

### Telescope Series

<Callout type="todo">
Add the proof for the telescope series, show visually why it is called a telescope series.
</Callout>

```math
\sum^{\infty}_{n=1}{\frac{1}{n(n+1)}}
```

converges to 1.

### Beware of Infinite Sums

An important note:
In the case of series we can not just use our usual rules for the [sum operator](/garden/maths/calculus/sequencesAndSeries/sumOperator). The reason is because the sums go to infinity and we can not just use the normal rules of arithmetic.

So if we have a series $\sum^{\infty}_{k=1}{a_k}$ und $\sum^{\infty}_{j=1}{b_j}$ and they converge then the following rules apply:
1. $\sum^{\infty}_{k=1}{c*a_k}=c* \sum^{\infty}_{k=1}{a_k}$ f체r $c \in C$
2. $\sum^{\infty}_{k=1}{a_k\pm b_k}=\sum^{\infty}_{k=1}{a_k}\pm \sum^{\infty}_{k=1}{b_k}$

For this lets compare two example $\sum^{\infty}_{n=1}{\frac{1}{n(n+1)}$ into $\sum^{\infty}_{n=1}{\frac{1}{n}} - \sum^{\infty}_{n=1}{\frac{1}{n+1}}$ We already know this is the telescoping series that converges to 1. So in this infinity minus infinity case we get 1.

But if we try to do the same for the value of 0 and the sum over 0. We can split it into $\sum^{\infty}_{n=1}{1} - \sum^{\infty}_{n=1}{1}$ which is not correct as these then diverge and we suddenly get a value of 1 (infinity minus infinity).