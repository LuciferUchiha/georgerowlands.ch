import Callout from "@components/Callout/Callout";
import Image from "@components/Image/Image";

# Differentiable Functions

We know that for a linear function with one variable we have the standard equation:

```math
y = mx + b
```

Where $m$ is the slope of the line and $b$ is the y-intercept. For the line defined by the function $f(x)$ finding the slope is easy by reordering the equation to the standard form. And because it is a line the slope is constant, so the same for all points $x_0$ in the domain of the function. However, what if we wanted to find the slope of a non-linear function at some point $x_0$? This is what the derivate is for. 

<Callout type="todo">
Add image of linear function with slope and y-intercept. and a non-linear function with a point $x_0$ and the slope at that point.
</Callout>

First let's just start with an approximation of the slope. For this we can define a **secant line** that goes through two points on the function. The slope of this secant line is then the so called **difference quotient**. So if we want to find the slope of the function $f$ at the point $x_0$, we can take a second point $x_1$ and calculate the slope of the secant line that goes through the points $P_0(x_0, f(x_0))$ and $P_1(x_1, f(x_1))$. We can then define the slope of the secant line as the difference of the function values divided by the difference of the $x$ values:

```math
m = \frac{f(x_1) - f(x_0)}{x_1 - x_0} = \frac{\Delta f}{\Delta x}
```

Hence it is called the difference quotient. 

<Callout type="todo">
Add image of different secant lines with different $x_1$ values.
</Callout>

Depending on the choice of $x_1$ this will give us a different slope. We can see if we choose $x_1$ very close to $x_0$, we get a better approximation of the slope at the point $x_0$. This leads us to the next idea, finding the slope of the tangent line at the point $x_0$. The slope of this tangent line is the derivative of the function at the point $x_0$. We get the tangent line by taking the limit of the difference quotient as $x_1$ approaches $x_0$. A common way of writing this is by defining the point $x_1$ with a small change denoted by $\Delta x$ or $h$. To then approach $x_0$ we can let $\Delta x$ or $h$ approach zero. This gives us the following definition of the derivative:

```math
m = \lim_{\Delta x \to 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x} = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}
```

<Callout type="todo">
Add image of tangent line at point $x_0$ with the slope defined by the limit of the difference quotient. What are actually the origin of sekant and tangent lines? Probably from trigonometry.
</Callout>

Using the derivate which is just the slope of the tangent line we can then find the equation of the tangent line at the point $x_0$, all we are missing the y-intercept $b$. We get this be reordering the equation of the tangent line to the point-slope form:

```math
b = f(x_0) - m \cdot x_0
```

So the equation of the tangent line is:

```math
T(x) = f(x_0) + m \cdot (x - x_0)
```

Where $m$ is the derivative of the function at the point $x_0$. Now we can formally define differentiable functions. We say that a function $f$ is differentiable at the point $x_0$ if $x_0$ is an [accumulation point]() of the domain of $f$ and the limit of the difference quotient exists, i.e. the derivate exists at the point $x_0$:

```math
f \text{ is differentiable at } x_0 \iff \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h} \text{ exists}
```

We denote this limit as $f'(x_0)$ or $\frac{df}{dx}(x_0)$, which is the derivative of the function $f$ at the point $x_0$. We say a function is differentiable on $D$ if it is differentiable at every point in the domain $D$. If this is the case then we can define the derivative function $f'$ as:

```math
f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} \forall x \in D
```

<Callout type="example" title="Constant Function">
Let us look at the derivative of some common functions to get a better understanding of differentiable functions. The constant function is defined as follows:

```math
f(x) = c \quad \forall x \in D
```

We can calculate the derivative of this function at any point $x_0$ in the domain $D$:

```math
\begin{align*}
\lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0} &= \lim_{x \to x_0} \frac{c - c}{x - x_0} \\
&= \lim_{x \to x_0} \frac{0}{x - x_0} \\
&= 0
\end{align*}
```

Therefore the derivative of the constant function for any $c \in \mathbb{R}$ and any point $x_0 \in D$ is:

```math
f'(x_0) = 0
```
</Callout>
<Callout type="example" title="Linear Function">

A (non-constant) linear function has the form  

```math
f(x) = mx + b \quad \forall x \in D
````

We can find the derivative at an arbitrary point $x_0 \in D$ as follows:

```math
\begin{align*}
\lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0}
&= \lim_{x \to x_0} \frac{m x + b - (m x_0 + b)}{x - x_0} \\
&= \lim_{x \to x_0} \frac{m(x - x_0)}{x - x_0} \\
&= \lim_{x \to x_0} m = m.
\end{align*}
```

Hence the derivative of any linear function is the slope itself:

```math
f'(x_0) = m.
```

Because the slope is constant, the function is differentiable everywhere and $f'(x)=m$ for all $x \in D$.
</Callout>
<Callout type="example" title="Quadratic Function">

Next we consider the simple quadratic (squared) function:

```math
f(x) = x^{2} \quad \forall x \in D.
````

To find the derivative at an arbitrary point $x_{0}\in D$ we apply the limit definition:

```math
\begin{align*}
\lim_{x \to x_{0}} \frac{f(x) - f(x_{0})}{x - x_{0}}
&= \lim_{x \to x_{0}} \frac{x^{2} - x_{0}^{2}}{x - x_{0}} \\
&= \lim_{x \to x_{0}} \frac{(x - x_{0})(x + x_{0})}{x - x_{0}} \\
&= \lim_{x \to x_{0}} (x + x_{0}) \\
&= 2x_{0}.
\end{align*}
```

Hence the derivative of $f(x)=x^{2}$ is for any point $x \in D$:

```math
f'(x) = 2x.
```

Because the tangent at any point has slope $2x$ the function is differentiable everywhere on its domain. An alternative approach would've been to use the formulation with $h$ instead of $x_0$:

```math
\begin{align*}
\lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}
&= \lim_{h \to 0} \frac{(x_0 + h)^{2} - x_{0}^{2}}{h} \\
&= \lim_{h \to 0} \frac{x_0^{2} + 2x_0 h + h^{2} - x_{0}^{2}}{h} \\
&= \lim_{h \to 0} \frac{2x_0 h + h^{2}}{h} \\
&= \lim_{h \to 0} (2x_0 + h) \\
&= 2x_0.
\end{align*}
```
</Callout>
<Callout type="example" title="Absolute Value Function">
The absolute-value function is defined piecewise:

```math
f(x)=
\begin{cases}
x & \text{if } x \geq 0,\\
-x & \text{if } x < 0.
\end{cases}
```

So to find the derivative we need to look at the two cases separately. We start with the case where $x_0>0$:

```math
\begin{align*}
\lim_{x \to x_0} \frac{f(x)-f(x_0)}{x-x_0}
  &= \lim_{x \to x_0} \frac{x - x_0}{x - x_0} = 1.
\end{align*}
```

So $f'(x_0)=1$. If we look at the case where $x_0<0$:

```math
\begin{align*}
\lim_{x \to x_0} \frac{f(x)-f(x_0)}{x-x_0}
  &= \lim_{x \to x_0} \frac{-x + x_0}{x - x_0}
  = \lim_{x \to x_0} \frac{-(x - x_0)}{x - x_0} = -1.
\end{align*}
```

So $f'(x_0)=-1$. Lastly we need to look at the case where $x_0=0$. In this case we have to look at the left and right limits separately as 

```math
\lim_{x \to 0^{+}} \frac{f(x)-f(0)}{x}
 = 1,
\qquad
\lim_{x \to 0^{-}} \frac{f(x)-f(0)}{x}
 = -1,
```

and because the two one-sided limits are not equal the limit does not exist as the difference approaches 0, so the derivative also does not exist at $x=0$. Putting this together we get the following piecewise definition of the derivative of the absolute value function:

```math
f'(x)=
\begin{cases}
 1, & x>0,\\
-1, & x<0,\\
\text{undefined}, & x=0.
\end{cases}
```

Thus $|x|$ is differentiable everywhere except for $x=0$.
</Callout>
<Callout type="example" title="Van der Waerden Function">

Van der Waerden function. Everywhere continous but nowhere differentiable.
</Callout>

## Tangent as an Approximation

It turns out that the tangent line is actually a pretty good approximation of the function in the area around the point $x_0$. This is useful because the tangent line is a simple linear function that we can easily work with and calculate with, whereas the original function might be more complex and expensive to compute. So we can approximate the function as follows:

```math
f(x) = T(x) + R_{x_0}(x)
```

Where $T(x)$ is the tangent line at the point $x_0$ and $R_{x_0}(x)$ is the remainder term. If $x \neq x_0$ Then we can rewrite this as:

```math
\begin{align*}
f(x) &= T(x) + R_{x_0}(x) \\
f(x) &= (f(x_0) + f'(x_0)(x - x_0)) + R_{x_0}(x) \\
f(x) - f(x_0) &= f'(x_0)(x - x_0) + R_{x_0}(x) \\
\frac{f(x) - f(x_0)}{x - x_0} &= f'(x_0) + \frac{R_{x_0}(x)}{x - x_0} \\
\lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0} &= f'(x_0) + \lim_{x \to x_0} \frac{R_{x_0}(x)}{x - x_0} \\
f'(x_0) &= f'(x_0) + \lim_{x \to x_0} \frac{R_{x_0}(x)}{x - x_0} \\
\lim_{x \to x_0} \frac{R_{x_0}(x)}{x - x_0} &= 0
\end{align*}
```

This means that as $x$ approaches $x_0$, the remainder term approaches zero faster than the difference of the points on the function. So for the limit to be zero the remainder term is always a small value compared to the difference of the points on the function. This is a very useful property of differentiable functions and allows us to use the tangent line as an approximation of the function in the area around the point $x_0$. If we define the remainder term as follows:

```math
r(x) = \begin{cases}
\frac{R_{x_0}(x)}{x - x_0} & \text{if } x \neq x_0 \\
0 & \text{if } x = x_0
\end{cases}
```

Then because we have $\lim_{x \to x_0} r(x) = 0 = r(x_0)$, we can say that the remainder term is continuous at the point $x_0$ because the limit is equal to the value, "filling" the original discontinuity hole. Because it is continuous it follows that if the function is also differentiable at $x_0$, then by the definition there exists some $m = f'(x_0)$ such that:

```math
f(x) = f(x_0) + f'(x_0)(x - x_0) + r(x)(x - x_0)
```

where $r(x_0) = 0$ and $f(x_0) + f'(x_0)(x - x_0) = mx + b$ is the equation of the tangent line at the point $x_0$.
This leads to the so called Weierstrass' differentiability criterion theorem which states that if a function is differentiable at a point and there exists some $c \in \mathbb{R}$ and function $r(x)$ that is continuous at $x_0$ such that the following holds:

```math
f(x) = f(x_0) + c (x - x_0) + r(x)(x - x_0)
```

Then the derivative $f'(x_0) = c$ is unique. This can be shown by assuming that there is another derivative $c$ and matching remainder term $s(x)$.

## Continuity of Differentiable Functions

Intuitively, differentiability is the "stronger" property then continuity, if you can zoom in far enough that a function looks perfectly linear, then its graph also can't have any jumps or holes at that point. However, we can also formally show this by using the definition of differentiability. Specifically, we can show that if a function $f$ is differentiable at a point $x_0$, then it is also continous at that point because then there exists some function $g$ that is continuous at $x_0$ such that the following holds:

```math
f(x) = f(x_0) + g(x)(x - x_0)
```

Where $g(x)=f'(x_0)$ is the derivative of $f$ at the point $x_0$. So for example $g$ could be for the linear function $f(x) = mx + b$ the slope $m$ of the tangent line at the point $x_0$. From this it follows that if $x_0$ is an accumulation point of the domain and the derivative exists, then the function is continuous at that point. 

```math
f \text{ is differentiable at } x_0 \implies f \text{ is continuous at } x_0
```

Then if a function is differentiable for all $x \in D$, then it is also continuous for all $x \in D$:

```math
f \text{ is differentiable on } D \implies f \text{ is continuous on } D
```

However, the converse is not true, i.e. a function can be continuous at a point but not differentiable at that point. A common example of this is the absolute value function which is continuous everywhere as $\lim_{x \to 0} |x| = 0 = |0|$ but not differentiable at $x_0 = 0$ because the left and right limits of the derivative at that point are not equal:

```math 
\lim_{x \to 0^{+}} \frac{|x| - |0|}{x - 0} = 1 \neq -1 = \lim_{x \to 0^{-}} \frac{|x| - |0|}{x - 0}
```

<Callout type="example" title="Exponential Function">
We already know that the exponential function is continuous everywhere. However, if we didn't know this, we could show that it is differentiable at any point $x_0$ in its domain which would then imply that it is also continuous at that point. We can find the derivative of the exponential function $f(x) = e^x = \exp(x)$ at an arbitrary point $x_0$ as follows. First we look at the difference:

```math
\begin{align*}
f(x_0 + h) - f(x_0) &= \exp(x_0 + h) - \exp(x_0) \\
&= \exp(x_0) \cdot \exp(h) - \exp(x_0) \\
&= \exp(x_0) (\exp(h) - 1)
\end{align*}
```

Then we can divide this by $h$ and take the limit as $h$ approaches zero:

```math
\begin{align*}
\lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h} &= \lim_{h \to 0} \frac{\exp(x_0) (\exp(h) - 1)}{h} \\
&= \exp(x_0) \cdot \lim_{h \to 0} \frac{\exp(h) - 1}{h} \\
&= \exp(x_0) \cdot 1 = \exp(x_0)
\end{align*}
```

So the derivative of the exponential function at any point $x_0$ is the exponential function itself:

```math
\exp'(x_0) = \exp(x_0)
```

The tricky part here is showing that the limit $\lim_{h \to 0} \frac{\exp(h) - 1}{h} = 1$ exists. This can be shown using the definition of the exponential function as a power series:

```math
\begin{align*}
\exp(h) = \sum_{n=0}^{\infty} \frac{h^n}{n!} = 1 + h + \frac{h^2}{2!} + \frac{h^3}{3!} + \ldots \\
\exp(h) - 1 = h + \frac{h^2}{2!} + \frac{h^3}{3!} + \ldots \\
\frac{\exp(h) - 1}{h} = 1 + \frac{h}{2!} + \frac{h^2}{3!} + \ldots
\end{align*}
```
</Callout>
<Callout type="example" title="Sine and Cosine Functions">
We can also look at the sine and cosine functions which are also continuous everywhere. We can find the derivative of the sine function at an arbitrary point $x_0$ in its domain by using the useful addition formula $\sin(a+b)=\sin a\cos b+\cos a\sin b$:

```math
\begin{align*}
\sin'(x_{0})
&=\lim_{h\to 0}\frac{\sin(x_{0}+h)-\sin x_{0}}{h} \\
&=\lim_{h\to 0}\frac{\sin x_{0}\cos h+\cos x_{0}\sin h-\sin x_{0}}{h}\\
&=\sin x_{0}\underbrace{\lim_{h\to 0}\frac{\cos h-1}{h}}_{=0}
  +\cos x_{0}\underbrace{\lim_{h\to 0}\frac{\sin h}{h}}_{=1}\\
&=\cos x_{0}
\end{align*}
```

Key here is that $\lim_{h\to 0}\frac{\sin h}{h}=1$ and $\lim_{h\to 0}\frac{\cos h-1}{h}=0$, which again can be shown using the there underlying power series definitions of the sine and cosine functions:

```math
\begin{align*}
\sin(h) = h - \frac{h^3}{3!} + \frac{h^5}{5!} - \ldots \\
\frac{\sin(h)}{h} = 1 - \frac{h^2}{3!} + \frac{h^4}{5!} - \ldots \\
\lim_{h \to 0} \frac{\sin(h)}{h} = 1
\text{ and } \\
\cos(h) = 1 - \frac{h^2}{2!} + \frac{h^4}{4!} - \ldots \\
\frac{\cos(h) - 1}{h} = -\frac{h}{2!} + \frac{h^3}{4!} - \ldots \\
\lim_{h \to 0} \frac{\cos(h) - 1}{h} = 0
\end{align*}
```

Therefore we have:

```math
\sin'(x) = \cos x
```

Because the cosine function is defined for all $x \in \mathbb{R}$, the sine function is differentiable everywhere on $\mathbb{R}$ and thus continuous everywhere on $\mathbb{R}$ as well.

Proceeding analogously for the cosine function we have:

```math
\begin{aligned}
\cos'(x_{0})
&=\lim_{h\to 0}\frac{\cos(x_{0}+h)-\cos x_{0}}{h}\\
&=\lim_{h\to 0}\frac{\cos x_{0}\cos h-\sin x_{0}\sin h-\cos x_{0}}{h}\\
&=\cos x_{0}\underbrace{\lim_{h\to 0}\frac{\cos h-1}{h}}_{=0}
  -\sin x_{0}\underbrace{\lim_{h\to 0}\frac{\sin h}{h}}_{=1}\\
&=-\sin x_{0}
\end{aligned}
```

Therefore we have:

```math
\cos'(x) = -\sin x
```
</Callout>

## Constant Rule

We have already seen in one of the examples that the derivative of a constant function is zero. This is a fundamental rule in calculus and is known as the **constant rule**. 

```math
f(x)=c \quad \Longrightarrow \quad f'(x)=0,\qquad \forall c \in\mathbb R
```

## Factor Rule

Another rule that is very useful is the **factor rule**. It states that if we have a function that is a constant multiple of another function, then the derivative of that function is just the constant multiplied by the derivative of the other function. More formally:

```math
f(x)=c\cdot g(x) \quad \Longrightarrow \quad f'(x)=c \cdot g'(x),\qquad \forall c \in\mathbb R
```

We can see this by looking at the limit definition of the derivative at any point $x_0$ in the domain of $g$,

```math
\begin{align*}
f'(x_0)
&=\lim_{h\to 0}\frac{f(x_0+h)-f(x_0)}{h} \\
&=\lim_{h\to 0}\frac{c g(x_0+h)-c g(x_0)}{h} \\
&=c \lim_{h\to 0}\frac{g(x_0+h)-g(x_0)}{h} \\
&=c g'(x_0)
\end{align*}
```

<Callout type="example">
As an example, let's look at the derivative of the following function:

```math
f(x) = 5\sin x
```

Because 5 is a constant it just gets factored out of the limit and we are left with the derivative of the sine function, which we already know is $\cos x$. So we can write:

```math
\begin{align*}
f'(x)
&= \lim_{h\to 0}\frac{5\sin(x+h)-5\sin x}{h} \\
&= 5\lim_{h\to 0}\frac{\sin(x+h)-\sin x}{h} \\
&= 5\cos x
\end{align*}
```
</Callout>

## Summation Rule

The **summation rule** states that the derivative of the sum of two functions is the sum of the derivatives of those functions. More formally, if we have two functions $a$ and $b$, then:

```math
f(x)=a(x)\pm b(x)\quad\Longrightarrow\quad f'(x)=a'(x)\pm b'(x)
```

Again, we can see this by looking at the limit definition of the derivative at any point $x_0$ in the domain of $a$ and $b$:

```math
\begin{align*}
f'(x_0)
&=\lim_{h\to 0}\frac{a(x_0+h)\!\pm\! b(x_0+h)-[a(x_0)\!\pm\! b(x_0)]}{h}\\
&=\lim_{h\to 0}\left[\frac{a(x_0+h)-a(x_0)}{h}\right]
 \pm \lim_{h\to 0}\left[\frac{b(x_0+h)-b(x_0)}{h}\right]\\
&=a'(x_0)\pm b'(x_0)
\end{align*}
```

<Callout type="example">
Let us look at the following function:

```math
f(x)=3x^{2}+5x-7
```

We already know that the derivative of $x^2$ is $2x$ and the derivative of $x$ is $1$. So we can apply the summation rule along with the factor rule to find the derivative of $f$:

```math
\begin{align*}
f'(x)
&= 3\cdot 2x + 5\cdot 1 + 0 \\
&= 6x + 5
\end{align*}
```
</Callout>

## Product Rule

We often need to differentiate the product of two functions. The **product rule** states that if $f(x)$ is the product of two functions $a(x)$ and $b(x)$, then the derivative of $f$ is given by:

```math
f(x)=a(x)b(x) \quad\Longrightarrow\quad 
f'(x)=a'(x)b(x)+a(x)b'(x)
```

Again we can derive this by looking at the limit definition of the derivative at any point $x_0$ in the domain of $a$ and $b$:

```math
\begin{align*}
f'(x_0)
&=\lim_{h\to 0}\frac{a(x_0+h)b(x_0+h)-a(x_0)b(x_0)}{h}\\
&=\lim_{h\to 0}\frac{a(x_0+h)b(x_0+h)-a(x_0)b(x_0+h)
                 +a(x_0)b(x_0+h)-a(x_0)b(x_0)}{h}\\
&=\lim_{h\to 0}\bigg[
     b(x_0+h)\frac{a(x_0+h)-a(x_0)}{h}
   +a(x_0)\frac{b(x_0+h)-b(x_0)}{h}\bigg]\\
&=b(x_0)a'(x_0)+a(x_0)b'(x_0)
\end{align*}
```

<Callout type="example">
We can apply the product rule to find the derivative of the following function:

```math
f(x)=x^{2}\sin x.
```

We can identify $a(x)=x^{2}$ and $b(x)=\sin x$. We already know that the derivative of $x^{2}$ is $2x$ and the derivative of $\sin x$ is $\cos x$. So we can apply the product rule to get the following:

```math
\begin{align*}
f'(x)
&= a'(x)b(x) + a(x)b'(x) \\
&= 2x\sin x + x^{2}\cos x.
\end{align*}
```
</Callout>

## Quotient Rule

Just like we have the product rule for the product of two functions, we also have a **quotient rule** for the quotient of two functions. So if $f(x)$ is the quotient of two functions $a(x)$ and $b(x)$ and $b(x) \neq 0$ then the derivative of $f$ is given by:

```math
f(x)=\frac{a(x)}{b(x)} \quad\Longrightarrow\quad
f'(x)=\frac{a'(x)b(x)-a(x)b'(x)}{[b(x)]^{2}} 
```

Again we can derive this by looking at the limit definition of the derivative at any point $x_0$ in the domain of $a$ and $b$ where $b(x_0) \neq 0$. Importantly, we use the product rule and $b^{-1}(x)$ for the derivative of the reciprocal function:

```math
\begin{align*
f'(x)
&=a'(x)b^{-1}(x)+a(x)(b^{-1}(x))'\\
&=a'(x)b^{-1}(x)-a(x)b^{-2}(x)b'(x)\\
&=\frac{a'(x)}{b(x)}-\frac{a(x)b'(x)}{[b(x)]^{2}}\\
&=\frac{a'(x)b(x)-a(x)b'(x)}{[b(x)]^{2}}
\end{align*}
```

<Callout type="example" title="Derivative of Tangent and Cotangent Functions">
The tangent function is defined as the quotient of the sine and cosine functions:

```math
f(x)=\tan x=\frac{\sin x}{\cos x}.
```

So we can apply the quotient rule to find the derivative of the tangent function with our known derivatives of the sine and cosine functions:

```math
\begin{align*}
f'(x)
&=\frac{\cos x \cdot \cos x - \sin x \cdot (-\sin x)}{(\cos x)^{2}} \\
&=\frac{\cos^{2} x + \sin^{2} x}{(\cos x)^{2}} \\
&=\frac{1}{(\cos x)^{2}} = \sec^{2} x.
\end{align*}
```

Note that we used the Pythagorean identity $\sin^{2} x + \cos^{2} x = 1$ to simplify the expression and that the tangent function is not defined for $x = (2k + 1)\frac{\pi}{2}$ where $k \in \mathbb{Z}$ because the cosine function is zero at these points, making the denominator zero.

We can then do the same for the cotangent function which is defined as the quotient of the cosine and sine functions. Here again we can apply the quotient rule with our known derivatives of the sine and cosine functions and note that the cotangent function is not defined for $x = k\pi$ where $k \in \mathbb{Z}$ because the sine function is zero at these points, making the denominator zero:

```math
f(x)=\cot x=\frac{\cos x}{\sin x}.
```

Which gives us:

```math
\begin{align*}
f'(x)
&=\frac{\sin x \cdot (-\sin x) - \cos x \cdot \cos x}{(\sin x)^{2}} \\
&=\frac{-\sin^{2} x - \cos^{2} x}{(\sin x)^{2}} \\
&=-\frac{1}{(\sin x)^{2}} = -\csc^{2} x.
\end{align*}
```
</Callout>

## Power Rule (integer exponent)

For $n\in\mathbb N$,

```math
f(x)=x^{n}\quad\Longrightarrow\quad f'(x)=n\,x^{\,n-1}.
```

**Derivation (by induction using the product rule)**

*Base case* $n=1$ is trivial.
*Inductive step*: assume the rule holds for some $n=k$.  For $n=k+1$,

```math
x^{k+1}=x^{k}\cdot x
\quad\Longrightarrow\quad
\frac{d}{dx}x^{k+1}
= k\,x^{k-1}\cdot x + x^{k}\cdot 1
=(k+1)x^{k}.
```

Thus the rule holds for all positive integers $n \in \mathbb N$. Once we have seen the chain rule, we can extend this to all real numbers $n \in \mathbb R$ using the exponential function.

## Chain Rule

Unter der Verkettung der Funktionen $g$ und $h$ versteht man die Nacheinanderausführung der Funktionen. Man wendet die äussere Funktion $g$ auf das Ergebnis der inneren Funktion $h$. Also von innen nach aussen.
$f(x)=g(h(x)) \iff f(x)=(g \circ h)(x)$

Man setzt für die innere Funktion: $z=h(x)$
so dass sich für die äussere Funktion $f=g(z)=g(h(x))$

```mathf(x)=g(h(x)) \Rightarrow f'(x)=g'(z)*h'(x)```

```ad-example
![[Pasted image 20211024170605.png]]
```

## Inverse Function Rule

Die Funktion $f(x)$ sei differenzierbar mit der Ableitung $f'(x)$ und besitzt die Umkehrfunktion $x = g(y)$. Die Ableitung der Umkehrfunktion $g(y)$ ist
```mathg'(y)={1\over f'(x)}```

```ad-example
![[Pasted image 20211024172038.png]]
```

## L'Hospital's Rule

## Higher Order Derivatives



## Ableitung der Logarithmusfunktion

```mathf(x)=log_a(x) \Rightarrow f'(x)= \frac{1}{x * ln(a)}```
wenn $f(x)=ln(x) \Rightarrow f'(x)= \frac{1}{x}$

```ad-example
![[Pasted image 20211024171755.png|100]]
```
