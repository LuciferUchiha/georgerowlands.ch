
# Random Forests

The idea of Random Forests is to build many decision trees for the same problem but that are slightly different. To then get the 
final prediction, we take the average of all the predictions of the different trees. This is called an ensemble method.

## Building a Random Forest

We will build a random forest to predict the survival of passengers on the Titanic. 

### Bagging - Bootstrap Aggregation

The idea of bagging is to build many models on different subsets of the data and then to average the predictions. So for each 
decision tree we build, we will use a different subset of the data.

where did the name come from?

This should improve the performance and prevent overfitting.

