import Image from "~/components/Image/Image";
import Callout from "~/components/Callout/Callout";

# AVL Trees

With the [binary search tree](./binarySearchTrees) we tried to implement a dictionary that allows us to search, insert and remove elements in $O(\log n)$ time. 
We saw that we can implement these operations in $O(h)$ time where $h$ is the height of the tree. However, the height of the tree is dependent on 
the order in which the elements are added and that in the worst case the height of the tree can be $n$ which would make the operations $O(n)$. So 
we need to find a way to keep a tree "balanced" on both sides of the root which would lead to a height and time complexity of $O(\log n)$.

An initial idea is to keep the tree complete with the **Completeness property**, so that all levels are filled except possibly for the last level which is filled from left to right. 
This would lead to a height of $\log n$ and a time complexity of $O(\log n)$. However if we want to maintain this property with the **Search-tree property** 
we quickly notice that for each set of $n$ elements there is only one tree that fullfills both properties. And therefore the work to maintain this 
property is too high in $O(n)$ time.

<Image
    src="/cs/algdAVLComplete.png"
    caption="Unique complete binary search tree for a set of $n$ elements."
/>

So we need to come up with a property that is less strict to be able to say a tree is balanced and have a time complexity of $O(\log n)$. This is where
the AVL tree comes in. The AVL Tree, named after its inventors Adelson-Velsky and Landis, is a self-balancing binary search tree. It is a binary search tree that satisfies the 
so called **AVL Property**:
> For every node $x$ in the tree, the difference in height between the left and right subtree of $x$ is at most 1.

So if we use the following notations:
- $T_l(v)$: the left subtree of node $v$
- $T_r(v)$: the right subtree of node $v$
- $h_l(v)$: the height of the left subtree of node $v$. But because we are talking about the height of the subtree and need to account for leaf 
nodes we increase the height by 1. So if $v$ is a leaf node then $h_l(v) = 0$ and otherwise $h_l(v) = 1 +$ the height of the left subtree of $v$.
- $h_r(v)$: the height of the right subtree of node $v$
- $bal(v)$: the balance factor of node $v$ so $bal(v) = h_r(v) - h_l(v)$

Then the we can say that a tree is balanced and satisfies the AVL property if:
> $|h_l(v) - h_r(v)| \leq 1$ or $|bal(v)| \leq 1$ for all nodes $v$ in the tree.

<Image
    src="/cs/algdAVLBalancedVsUnbalanced.png"
    caption="Comparison of balanced and unbalanced binary search trees."
/>

## AVL Tree height

Let's first check that this property actually leads to a height of $O(\log n)$. We can prove this by induction. We can use the fibonacci sequence and some of 
its properties to prove this. Specifically if $T(h)$ is the minimum number of nodes in an AVL tree of height $h$ then we can say that:

> An AVL tree of height $h$ has at least $Fib(h+1) - 1$ nodes, so $T(h) \geq Fib(h+1) - 1$.

Where $Fib(h)$ is the $h$-th fibonacci number and defined as:

$$
\begin{align*}
    Fib(1) &= 1 \\
    Fib(2) &= 1 \\
    Fib(n) &= Fib(n-1) + Fib(n-2) \text{ for } n \geq 2
\end{align*}
$$

<Callout type="proof">
We want to show that the minimum number of nodes in an AVL tree of height $h$ is $Fib(h+1) - 1$. So $T(h) \geq Fib(h+1) - 1$. 
Because the fibonacci sequence uses the previous 2 numbers we need to use strong induction.

1. **Base Case**: A tree of height 0 is just a leaf node so $T(0) = 1$ and $Fib(0+1) - 1 = 0$. 
The minimum number of nodes in an AVL tree of height 1 is the root node and 1 leaf node so $T(1) = 2$ and $Fib(1+1) - 1 = 0$. 
So the base case holds.
2. **Inductive Hypothesis**: We assume that the statement holds for all $h \leq k$.
3. **Inductive Step**: We want to show that the statement holds for $h = k+1$. Because of the AVL property we know that the trees left and right 
subtree have a height difference of at most 1. So the minimum number of nodes in an AVL tree of height $k+1$ can be defined as:
$$
\begin{align*}
    T(k+1) &= T(k) + T(k-1) + 1 \\
    &\overset{I.H}{\geq} Fib(k+1) - 1 + Fib(k) - 1 + 1 \\
    &= Fib(k+2) - 1
\end{align*}
$$
So the statement holds for $h = k+1$ and therefore for all $h$.
</Callout>

So we can see that the minimum number of nodes in an AVL tree of height $h$ is $Fib(h+1) - 1$. Because the fibonacci sequence grows exponentially we can 
say that the height of the tree is $O(\log n)$ where $n$ is the number of nodes in the tree.

## Maintaining a Balanced Tree

All of the operations, insert, search and remove work the same as with a binary tree. However, now after inserting or deleting we have to recalculate the balance factors of all of the nodes from the inserted/removed node. Important when a node was removed and replaced with its symmetrical successor we have to start at the lowest removed node. If after recalculating the balance factors the tree is no longer balanced we have to perform rebalancing operations till the tree is balanced again.

There are 3 situations when a tree is unbalanced which then lead to different rebalancing operations.

1. bal(p) and bal(v) have the same sign.
2. bal(v) = 0
3. bal(p) and bal(v) have deafferent signs.

<Image
    src="/cs/treesUnbalanced.png"
    caption="A binary tree."
/>

#### Simple Rotations

Situation 1 and 2 can be resolved with a simple rotation. Depending on which subtree has the higher absolute balance factor. If the left subtree is higher then the right subtree we perform a  **right rotation**. The other way around we perform a **left rotation**.

<Image
    src="/cs/treesAvlRotationRight.png"
    caption="A binary tree."
/>
![avlLeftRotation](/compSci/avlLeftRotation.png)
<Image
    src="/cs/treesAvlRotationLeft.png"
    caption="A binary tree."
/>

#### Double Rotations

We can't resolve situation 3 with a simple rotation we need to do a so called double rotation. Here again we have 2 options depending which subtree is higher. either a **right-left double rotation** or a **left-right double rotation**.

<Image
    src="/cs/treesAvlRotationRightLeft.png"
    caption="A binary tree."
/>
<Image
    src="/cs/treesAvlRotationLeftRight.png"
    caption="A binary tree."
/>

## Implementation

We can notice that we often need to know the balance factors of a node. This can be calculated every time using the heights however this is very bad for performance instead we should store the balance factors with the nodes and update them when needed.

### Insert

If we insert a new node *v* and its parent is *p* then we have the following situations

<Image
    src="/cs/treesAvlUpinSituations.png"
    caption="A binary tree."
/>

If the height of *p* doesn't change we just need to update the balance factor of *p* and are done. However if the height of *p* changes. So if the balance factor of *p* changes from 0 to +/-1 then we have to recursively update the balance factor of its parent *pp*. For this we use the so called upin(p) method.

#### Upin Case 1

If the height of *pp* doesn't change so the balance factor of *pp* changes from 0 to +/-1 we are done.

<Image
    src="/cs/treesAvlUpinCase1.png"
    caption="A binary tree."
/>

#### Upin Case 2

If the height of *pp* changes but the node stays balanced so the balance factor of *pp* changes from 0 to +/-1 we have to recursively update the balance factor of its parent with upin(pp).

#### Upin Case 3

If the height of *pp* changes and the node is no longer balanced so the balance factor of *pp* changes from +/-1 to +/- 2 we have to perform at the max 1 rotation.

### Remove

Here we use upout to update the balance factors however it can happen that more then 1 rotation is needed on the way to the root.


## Other Advantages of AVL Trees

An AVL tree can be used to implement a dictionary as we have already seen. But it can also be used to implement a priority queue. The minimum or 
maximum element can be extracted in $O(\log n)$ time by repeatedly traversing the left or right child of the root. But the AVL tree is less efficient 
as it will have a higher memory and time overhead compared to a heap. However, the AVL tree is a lot more flexible due to the fact of being a 
min and max heap at the same time and offering efficient search operations.

By always keeping track of how many nodes are in the left and right subtree of a node we can also find the $k$-th smallest or largest 
element in the tree in $O(\log n)$ time. For simplicity we will only consider the $k$-th smallest element as the $k$-th largest element is just 
the $n-k$-th smallest element.

<Callout type="todo">
    Implement the $k$-th smallest element search.
</Callout>
