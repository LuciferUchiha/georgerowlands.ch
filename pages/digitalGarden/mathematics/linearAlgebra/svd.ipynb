{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Singular Value Decomposition - SVD\n",
    "tags: [vectors, matrices, linear algebra]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigendecomposition only works for square matrices, the singular value decomposition, short SVD, is a generalization of the eigendecomposition allowing it to be used for rectangular matrices. Singular value decomposition uses 3 matrices just like the eigendecomposition.\n",
    "\n",
    "$$\\boldsymbol{A}=\\boldsymbol{U}\\Sigma\\boldsymbol{V}^T$$\n",
    "\n",
    "The first matrix $\\boldsymbol{U}$ is the so-called left singular value matrix which is an orthogonal matrix meaning $\\boldsymbol{UU}^T=\\boldsymbol{I}$, the second matrix $\\Sigma$ is the singular value matrix which is very just like the matrix containing the eigenvalues in the eigendecomposition a diagonal matrix. The last matrix $\\boldsymbol{V}^T$ is the right singular value matrix which is also an orthogonal matrix. To find the values we can do the following transformations which make it very similar to the eigendecomposition.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\boldsymbol{A}^T\\boldsymbol{A}=\\boldsymbol{V}\\Sigma^T\\boldsymbol{U}^T\\boldsymbol{U}\\Sigma\\boldsymbol{V}^T \\\\\n",
    "    \\boldsymbol{A}^T\\boldsymbol{A}=\\boldsymbol{V}(\\Sigma^T\\Sigma)\\boldsymbol{V}^T\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Because $\\Sigma$ is a diagonal matrix the multiplication with its transpose results again in a diagonal matrix. Which gives it the same form as the eigendecomposition. To get the matrix $\\boldsymbol{U}$ we can do something very similar.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\boldsymbol{A}\\boldsymbol{A}^T=\\boldsymbol{U}\\Sigma\\boldsymbol{V}^T\\boldsymbol{V}\\Sigma^T\\boldsymbol{U}^T \\\\\n",
    "    \\boldsymbol{A}\\boldsymbol{A}^T=\\boldsymbol{U}(\\Sigma\\Sigma^T)\\boldsymbol{U}^T\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.18214154,  1.89367286,  2.74943852],\n",
       "       [ 1.95955405,  5.01675209,  1.2880268 ],\n",
       "       [-2.7028794 ,  1.11633398, -5.07755598]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[-5,2,3], [2, 5, 1], [-3,1,-5]])\n",
    "e_values, e_vectors = np.linalg.eigh(A.T@A) # @ is same as np.matmul\n",
    "Sigma = np.diag(np.sqrt(e_values))\n",
    "V = e_vectors\n",
    "U = []\n",
    "for i in range(0, len(e_values)):\n",
    "    u_i = A@V[:,i]/np.linalg.norm(A@V[:,i])\n",
    "    U.append(u_i)\n",
    "U@Sigma@V.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we lose some precision due to floating number operations but these can be fixed using the round operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.,  2.,  3.],\n",
       "       [ 2.,  5.,  1.],\n",
       "       [-3.,  1., -5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(U@Sigma@V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also just use the built in svd of numpy which is more efficient and accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.,  2.,  3.],\n",
       "       [ 2.,  5.,  1.],\n",
       "       [-3.,  1., -5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, Sigma, Vh = np.linalg.svd(A)\n",
    "U@np.diag(Sigma)@Vh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Solving equations using svd???? Or only because we can solve equations using moore penrose and one way to compute is with SVD.\n",
    "\n",
    "## Image Compression\n",
    "\n",
    ":::todo\n",
    "low rank approximation\n",
    ":::\n",
    "\n",
    "## Principal Component Analysis - PCA\n",
    "\n",
    ":::todo\n",
    "This should probably be its own chapter\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4874554c910ab0571857260f9b3a2c29827abeee32c252ce8c2203a14b689e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
